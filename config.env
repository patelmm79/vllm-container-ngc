# ============================================================================
# Centralized Model Configuration
# ============================================================================
# This file contains the primary model configuration used throughout the project.
# Change the MODEL_NAME here to switch to a different model - it will automatically
# propagate to all components (Dockerfile, entrypoint.sh, prewarm_compile.py, etc.)

# Model Configuration
MODEL_NAME=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

# Derived values (automatically computed from MODEL_NAME)
# The HF_CACHE_DIR is the normalized model name used by Hugging Face cache
# Format: models--{org}--{model_name}
HF_CACHE_DIR=models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B

# Cloud Run Service Configuration
# This is used by cloudbuild.yaml and test scripts
SERVICE_NAME=vllm-deepseek-r1-1-5b

# Artifact Registry Configuration
ARTIFACT_REGISTRY_REPO=vllm-deepseek-r1-repo
ARTIFACT_REGISTRY_IMAGE=vllm-deepseek-r1-1-5b

# ============================================================================
# Google Cloud Labels for Cost Tracking
# ============================================================================
# These labels are applied to Cloud Run services and Cloud Build jobs for
# cost allocation and resource organization. Labels must follow GCP naming rules:
# - Keys and values must be lowercase
# - Start with a letter, contain only letters, numbers, underscores, hyphens
# - Maximum 63 characters

# Application labels
LABEL_APPLICATION=vllm-inference
LABEL_ENVIRONMENT=production
LABEL_TEAM=ml-platform
LABEL_COST_CENTER=engineering

# ============================================================================
# Instructions for Changing Models
# ============================================================================
# 1. Update MODEL_NAME to your desired model (e.g., "meta-llama/Llama-3.2-1B")
# 2. Update HF_CACHE_DIR to match the normalized format:
#    - Replace "/" with "--" and add "models--" prefix
#    - Example: meta-llama/Llama-3.2-1B â†’ models--meta-llama--Llama-3.2-1B
# 3. Optionally update SERVICE_NAME, ARTIFACT_REGISTRY_REPO, and
#    ARTIFACT_REGISTRY_IMAGE if you want different Cloud Run deployment names
# 4. Rebuild the container: gcloud builds submit --config cloudbuild.yaml
#
# Note: Ensure your HF_TOKEN has access to the model on Hugging Face Hub
