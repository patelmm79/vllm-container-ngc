# ============================================================================
# Local Development Environment Configuration
# ============================================================================
# This file is for local development only. For production deployments,
# the primary model configuration is in config.env (committed to the repo).
#
# To change models: Edit config.env (not this file)
# ============================================================================

# Hugging Face Token (required for downloading models during build)
HF_TOKEN=your_hugging_face_token_here

# Model Configuration (for local development overrides)
# Note: The primary model configuration is in config.env
# These values will override config.env if set locally
# MODEL_NAME=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
HF_HOME=/model-cache

# Server Configuration
PORT=8000
# MAX_MODEL_LEN=2048  # Optional: Set maximum model length

# CUDA Architecture Configuration
# This setting is optimized for Google Cloud Run which uses NVIDIA T4 GPUs
# NVIDIA T4 has compute capability 7.5
# Setting this reduces compilation time by avoiding compilation for all GPU architectures
TORCH_CUDA_ARCH_LIST=7.5

# Common GPU compute capabilities for reference:
# - NVIDIA T4 (Cloud Run): 7.5
# - NVIDIA V100: 7.0
# - NVIDIA A100: 8.0
# - NVIDIA H100: 9.0
# - RTX 3090/4090: 8.6
# - RTX 4000 series Ada: 8.9

# ============================================================================
# IMPORTANT: To change the model for this project
# ============================================================================
# Edit config.env (not this file) and update:
# 1. MODEL_NAME - the Hugging Face model identifier
# 2. HF_CACHE_DIR - the normalized cache directory name
# 3. SERVICE_NAME - the Cloud Run service name (optional)
# 4. ARTIFACT_REGISTRY_* - deployment configuration (optional)
